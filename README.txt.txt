# ğŸ“¦ Mini Trabalho 6 â€“ OtimizaÃ§Ã£o e Ajuste Fino dos Modelos de Machine Learning

## ğŸ¯ Objetivo

Este mini trabalho teve como foco a **otimizaÃ§Ã£o e ajuste fino dos modelos de aprendizado de mÃ¡quina** utilizados para prever a aprovaÃ§Ã£o de proposiÃ§Ãµes legislativas na CÃ¢mara dos Deputados.

Foram aplicadas tÃ©cnicas de ajuste de hiperparÃ¢metros com validaÃ§Ã£o cruzada para **maximizar a performance** dos modelos (Random Forest e XGBoost), reduzindo overfitting e melhorando a capacidade de generalizaÃ§Ã£o.

---

## ğŸ‘¥ Equipe e Responsabilidades

| Integrante         | Responsabilidade                                                                 |
|--------------------|----------------------------------------------------------------------------------|
| Pessoa 1           | OtimizaÃ§Ã£o do modelo **Random Forest** com GridSearchCV e validaÃ§Ã£o cruzada     |
| Pessoa 2           | OtimizaÃ§Ã£o do modelo **XGBoost** com RandomizedSearchCV e ajuste de parÃ¢metros   |
| Pessoa 3           | ImplementaÃ§Ã£o de validaÃ§Ã£o cruzada + anÃ¡lise de erros e mÃ©tricas de avaliaÃ§Ã£o    |
| Pessoa 4           | OrganizaÃ§Ã£o final dos notebooks, arquivos e documentaÃ§Ã£o (`README.txt`)          |

---

## ğŸ§ª Modelos Otimizados

### âœ… Random Forest (Pessoa 1)

- Utilizou `RandomizedSearchCV` com validaÃ§Ã£o cruzada (5-fold) para ajustar os hiperparÃ¢metros:
  - `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`
- Aplicou `class_weight=balanced` para corrigir desbalanceamento da classe alvo.
- MÃ©trica de avaliaÃ§Ã£o principal: **F1-score**
- Resultados:
  - **Melhor F1-score na validaÃ§Ã£o cruzada**: ~0.95
  - **ImportÃ¢ncia das features** plotada com `seaborn`
- Modelo final salvo como: `random_forest_otimizado.joblib`

- Resultados:
  - Melhor F1-score para a classe "1" (aprovada)
  - GrÃ¡fico de validaÃ§Ã£o para `max_depth` incluÃ­do

---

### âœ… XGBoost (Pessoa 2)

- Ajustou os hiperparÃ¢metros com `RandomizedSearchCV` e `StratifiedKFold`:
  - `learning_rate`, `n_estimators`, `max_depth`, `subsample`, `colsample_bytree`, `gamma`, `min_child_weight`
- ConfiguraÃ§Ã£o extra:
  - `use_label_encoder=False`
  - `eval_metric='logloss'`
- MÃ©tricas analisadas: **AcurÃ¡cia**, **F1-score**, **AUC-ROC**
- Resultados:
  - **Melhoria significativa de desempenho apÃ³s tuning**
  - **Feature importance** visualizada e interpretada
- Modelo pronto para exportaÃ§Ã£o via `joblib`

- ObservaÃ§Ãµes:
  - OtimizaÃ§Ã£o com 20 combinaÃ§Ãµes e 5 folds: total de 100 treinamentos
  - Monitoramento com `verbose` e suporte a `tqdm` se necessÃ¡rio
  - ReduÃ§Ã£o de warnings e melhora na performance geral
  - AUC e F1 melhoraram em comparaÃ§Ã£o ao modelo anterior

---

### âœ… ValidaÃ§Ã£o Cruzada e AnÃ¡lise de Erros (Pessoa 3)

- Aplicou `cross_val_score` com `f1_macro` e `StratifiedKFold` (5-fold)
- Utilizou `RandomForestClassifier` como baseline
- AnÃ¡lises realizadas:
  - DistribuiÃ§Ã£o de scores entre as folds com `boxplot`
  - Matriz de confusÃ£o com `seaborn.heatmap`
  - IdentificaÃ§Ã£o de **erros comuns**, como proposiÃ§Ãµes previstas como rejeitadas mas que foram aprovadas
- Insights relevantes para prÃ³ximas iteraÃ§Ãµes dos modelos


## ğŸ“‚ Estrutura da Entrega

ğŸ“ modelos_otimizados/
    â”œâ”€â”€ random_forest_otimizado.pkl
    â”œâ”€â”€ xgboost_otimizado.pkl

ğŸ“ resultados/
    â”œâ”€â”€ matriz_confusao_rf.png
    â”œâ”€â”€ matriz_confusao_xgb.png
    â”œâ”€â”€ grafico_importancia_rf.png
    â”œâ”€â”€ grafico_validacao_xgb.png

ğŸ“ notebooks/
    â”œâ”€â”€ otimizacao_random_forest.ipynb
    â”œâ”€â”€ otimizacao_xgboost.ipynb
    â”œâ”€â”€ validacao_cruzada_analise_erros.ipynb

ğŸ“„ README.txt


## ğŸ› ï¸ Como Executar

1. Certifique-se de ter as bibliotecas instaladas:
   - `scikit-learn`, `xgboost`, `matplotlib`, `seaborn`, `pandas`, `numpy`

2. Abra os notebooks em `/notebooks/` e execute cÃ©lula por cÃ©lula.

3. Para carregar os modelos otimizados:
```python
import joblib
modelo_rf = joblib.load('modelos_otimizados/random_forest_otimizado.pkl')
modelo_xgb = joblib.load('modelos_otimizados/xgboost_otimizado.pkl')


ConclusÃ£o
Os modelos otimizados apresentaram melhorias significativas nas mÃ©tricas de avaliaÃ§Ã£o.

A escolha criteriosa dos hiperparÃ¢metros e o uso da validaÃ§Ã£o cruzada aumentaram a robustez das previsÃµes.

As anÃ¡lises de erro e importÃ¢ncia das features trouxeram insights valiosos para futuras melhorias.